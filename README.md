# UTA-NET æ­Œè©ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ  ğŸµ

## ğŸ“– ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦

UTA-NETæ­Œè©ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã¯ã€æ—¥æœ¬æœ€å¤§ç´šã®æ­Œè©æ¤œç´¢ã‚µã‚¤ãƒˆã€Œuta-net.comã€ã‹ã‚‰æ¥½æ›²æƒ…å ±ã¨æ­Œè©ã‚’è‡ªå‹•åé›†ã™ã‚‹é«˜æ€§èƒ½Pythonãƒ„ãƒ¼ãƒ«ã§ã™ã€‚å¤§é‡ã®æ¥½æ›²ãƒ‡ãƒ¼ã‚¿ã‚’åŠ¹ç‡çš„ã«åé›†ã—ã€æ§‹é€ åŒ–ã•ã‚ŒãŸCSVå½¢å¼ã§ä¿å­˜ã™ã‚‹ã“ã¨ã§ã€éŸ³æ¥½ãƒ‡ãƒ¼ã‚¿åˆ†æã‚„ç ”ç©¶ç”¨é€”ã«æœ€é©åŒ–ã•ã‚Œã¦ã„ã¾ã™ã€‚

### ğŸŒŸ ã‚·ã‚¹ãƒ†ãƒ ã®ç‰¹å¾´

- **å®Œå…¨è‡ªå‹•åŒ–**: æ¥½æ›²IDåé›†ã‹ã‚‰æ­Œè©å–å¾—ã¾ã§å…¨å·¥ç¨‹ã‚’è‡ªå‹•åŒ–
- **å¤§è¦æ¨¡å‡¦ç†å¯¾å¿œ**: æ•°åƒæ›²è¦æ¨¡ã®ãƒ‡ãƒ¼ã‚¿åé›†ã«å¯¾å¿œ
- **å¢—åˆ†æ›´æ–°**: æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ä¿æŒã—ãªãŒã‚‰æ–°è¦æ¥½æ›²ã®ã¿ã‚’è¿½åŠ 
- **ã‚¨ãƒ©ãƒ¼è€æ€§**: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ã‚„ã‚µã‚¤ãƒˆæ§‹é€ å¤‰æ›´ã«æŸ”è»Ÿå¯¾å¿œ
- **é€²è¡ŒçŠ¶æ³å¯è¦–åŒ–**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€²æ—è¡¨ç¤ºã§å‡¦ç†çŠ¶æ³ã‚’ç›£è¦–
- **ãƒ‡ãƒ¼ã‚¿å“è³ªä¿è¨¼**: é‡è¤‡é˜²æ­¢ã¨æ¬ æãƒ‡ãƒ¼ã‚¿å¯¾å¿œ

## ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆ

### ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ
```
uta-net/
â”œâ”€â”€ scripts.py              # ãƒ¡ã‚¤ãƒ³ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¨ãƒ³ã‚¸ãƒ³
â”œâ”€â”€ lyrics_data.csv          # æ­Œè©ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆè‡ªå‹•ç”Ÿæˆï¼‰
â”œâ”€â”€ song_ids_134.csv         # æ¥½æ›²IDãƒªã‚¹ãƒˆï¼ˆè‡ªå‹•ç”Ÿæˆï¼‰
â”œâ”€â”€ dev.ipynb               # é–‹ç™ºãƒ»ãƒ†ã‚¹ãƒˆç”¨ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯
â”œâ”€â”€ main.ipynb              # ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œç”¨ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯
â”œâ”€â”€ requirements.txt         # ä¾å­˜é–¢ä¿‚å®šç¾©
â””â”€â”€ README.md               # ã‚·ã‚¹ãƒ†ãƒ èª¬æ˜æ›¸ï¼ˆã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
```

### ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

#### 1. `get_and_save_song_ids()` - æ¥½æ›²IDåé›†ã‚¨ãƒ³ã‚¸ãƒ³
```python
def get_and_save_song_ids(artist_page_url, filepath=None)
```
- **æ©Ÿèƒ½**: ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆãƒšãƒ¼ã‚¸ã‹ã‚‰å…¨æ¥½æ›²ã®IDã‚’åé›†
- **å¯¾å¿œ**: ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³è‡ªå‹•å‡¦ç†
- **å‡ºåŠ›**: `song_ids_{artist_id}.csv`

#### 2. `scrape_and_save_lyrics()` - æ­Œè©åé›†ã‚¨ãƒ³ã‚¸ãƒ³
```python
def scrape_and_save_lyrics(song_id_list, filepath=None, artist_id=None)
```
- **æ©Ÿèƒ½**: æ¥½æ›²IDãƒªã‚¹ãƒˆã‹ã‚‰è©³ç´°æƒ…å ±ã¨æ­Œè©ã‚’åé›†
- **å‡ºåŠ›**: `lyrics_data_{artist_id}.csv`

#### 3. `get_song_details_and_lyrics()` - æ¥½æ›²è©³ç´°å–å¾—ã‚¨ãƒ³ã‚¸ãƒ³
```python
def get_song_details_and_lyrics(song_id)
```
- **æ©Ÿèƒ½**: å˜ä¸€æ¥½æ›²ã®å…¨è©³ç´°æƒ…å ±ã‚’å–å¾—
- **æˆ»ã‚Šå€¤**: æ¥½æ›²ãƒ‡ãƒ¼ã‚¿è¾æ›¸

## ğŸš€ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¬ã‚¤ãƒ‰

### 1. ç’°å¢ƒæº–å‚™
```bash
# ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³
git clone <repository-url>
cd uta-net

# ä»®æƒ³ç’°å¢ƒã®ä½œæˆï¼ˆæ¨å¥¨ï¼‰
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements.txt
```

### 2. å¿…è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
```
requests>=2.28.0        # HTTPé€šä¿¡
beautifulsoup4>=4.11.0  # HTMLè§£æ
pandas>=1.5.0           # ãƒ‡ãƒ¼ã‚¿å‡¦ç†
tqdm>=4.64.0           # é€²è¡ŒçŠ¶æ³è¡¨ç¤º
```

## ğŸ“‹ ã‚·ã‚¹ãƒ†ãƒ ãƒ•ãƒ­ãƒ¼

### åŸºæœ¬çš„ãªå‡¦ç†ãƒ•ãƒ­ãƒ¼

```mermaid
graph TD
    A[ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆURLå…¥åŠ›] --> B[æ¥½æ›²IDåé›†é–‹å§‹]
    B --> C[ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å‡¦ç†]
    C --> D[æ¥½æ›²IDãƒªã‚¹ãƒˆç”Ÿæˆ]
    D --> E[æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã¨çµ±åˆ]
    E --> F[CSVä¿å­˜]
    F --> G[æ­Œè©åé›†é–‹å§‹]
    G --> H[æ¥½æ›²è©³ç´°å–å¾—]
    H --> I[æ­Œè©æŠ½å‡ºãƒ»æ•´å½¢]
    I --> J[ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°]
    J --> K[å‡¦ç†å®Œäº†]
```

### è©³ç´°ãªå®Ÿè¡Œãƒ•ãƒ­ãƒ¼

#### Phase 1: æ¥½æ›²IDåé›†
1. **ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆãƒšãƒ¼ã‚¸ã‚¢ã‚¯ã‚»ã‚¹**
   - æŒ‡å®šã•ã‚ŒãŸã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆURLã«ã‚¢ã‚¯ã‚»ã‚¹
   - HTMLãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å–å¾—ã¨æ¤œè¨¼

2. **ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å‡¦ç†**
   - 1ãƒšãƒ¼ã‚¸ç›®: ç›´æ¥ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆURL
   - 2ãƒšãƒ¼ã‚¸ç›®ä»¥é™: `/artist/{artist_id}/0/{page}/`å½¢å¼
   - æœ€å¤§100ãƒšãƒ¼ã‚¸ã¾ã§è‡ªå‹•å‡¦ç†

3. **æ¥½æ›²ãƒªãƒ³ã‚¯æŠ½å‡º**
   - ã‚¯ãƒ©ã‚¹ `py-2 py-lg-0` ã®`<a>`ã‚¿ã‚°ã‚’æ¤œç´¢
   - `/song/` ã‚’å«ã‚€hrefå±æ€§ã‹ã‚‰æ¥½æ›²IDã‚’æŠ½å‡º

4. **ãƒ‡ãƒ¼ã‚¿çµ±åˆã¨ä¿å­˜**
   - æ—¢å­˜CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
   - æ–°è¦IDã®ã¿ã‚’è¿½åŠ ï¼ˆé‡è¤‡æ’é™¤ï¼‰
   - ã‚½ãƒ¼ãƒˆæ¸ˆã¿ãƒªã‚¹ãƒˆã¨ã—ã¦ä¿å­˜

#### Phase 2: æ­Œè©åé›†
1. **å‡¦ç†å¯¾è±¡ã®æ±ºå®š**
   - æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®èª­ã¿è¾¼ã¿
   - æœªå‡¦ç†æ¥½æ›²IDã®ç‰¹å®š

2. **æ¥½æ›²è©³ç´°å–å¾—**
   - å„æ¥½æ›²ãƒšãƒ¼ã‚¸ã¸ã®å€‹åˆ¥ã‚¢ã‚¯ã‚»ã‚¹
   - HTMLè§£æã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿æŠ½å‡º

3. **ãƒ‡ãƒ¼ã‚¿æ§‹é€ åŒ–**
   - ä»¥ä¸‹ã®æƒ…å ±ã‚’ä½“ç³»çš„ã«åé›†:
     - åŸºæœ¬æƒ…å ±: ã‚¿ã‚¤ãƒˆãƒ«ã€ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆã€æ¥½æ›²ID
     - åˆ¶ä½œæƒ…å ±: ä½œè©è€…ã€ä½œæ›²è€…ã€ç·¨æ›²è€…
     - ãƒªãƒªãƒ¼ã‚¹æƒ…å ±: ç™ºå£²æ—¥ã€ä¸»é¡Œæ­Œæƒ…å ±
     - ãƒ¡ãƒ‡ã‚£ã‚¢: ã‚«ãƒãƒ¼ç”»åƒURL
     - æ­Œè©: å®Œå…¨ãªãƒ†ã‚­ã‚¹ãƒˆ

4. **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°**
   - CSVå½¢å¼ã§ã®é€æ¬¡ä¿å­˜
   - UTF-8ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¯¾å¿œ

## ğŸ¯ ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³•

#### 1. ç°¡å˜ãªå®Ÿè¡Œä¾‹
```python
import scripts

# Step 1: æ¥½æ›²IDã‚’åé›†
artist_url = "https://www.uta-net.com/artist/134/"
song_ids = scripts.get_and_save_song_ids(artist_url)
print(f"åé›†ã—ãŸæ¥½æ›²æ•°: {len(song_ids)}ä»¶")

# Step 2: æ­Œè©ã‚’ä¸€æ‹¬å–å¾—
scripts.scrape_and_save_lyrics(song_ids, artist_id="134")
print("æ­Œè©åé›†å®Œäº†")
```

#### 2. ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºä¾‹
```python
# ã‚«ã‚¹ã‚¿ãƒ ãƒ•ã‚¡ã‚¤ãƒ«åã§ã®ä¿å­˜
song_ids = scripts.get_and_save_song_ids(
    artist_page_url="https://www.uta-net.com/artist/134/",
    filepath="my_custom_song_ids.csv"
)

# ç‰¹å®šã®æ¥½æ›²ãƒªã‚¹ãƒˆã‹ã‚‰æ­Œè©ã‚’å–å¾—
selected_songs = ["123456", "234567", "345678"]
scripts.scrape_and_save_lyrics(
    song_id_list=selected_songs,
    filepath="selected_lyrics.csv",
    artist_id="134"
)
```

#### 3. å€‹åˆ¥æ¥½æ›²å‡¦ç†
```python
# å˜ä¸€æ¥½æ›²ã®è©³ç´°å–å¾—
song_data = scripts.get_song_details_and_lyrics("123456")
print(f"ã‚¿ã‚¤ãƒˆãƒ«: {song_data['title']}")
print(f"ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆ: {song_data['artist']}")
print(f"æ­Œè©:\n{song_data['lyrics']}")

# å¾Œæ–¹äº’æ›æ€§é–¢æ•°ã®ä½¿ç”¨
title, lyrics = scripts.get_song_title_and_lyrics("123456")
```

### å¿œç”¨çš„ãªä½¿ç”¨æ–¹æ³•

#### ãƒãƒƒãƒå‡¦ç†
```python
# è¤‡æ•°ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆã®ä¸€æ‹¬å‡¦ç†
artists = [
    "https://www.uta-net.com/artist/134/",
    "https://www.uta-net.com/artist/256/",
    "https://www.uta-net.com/artist/789/"
]

for artist_url in artists:
    try:
        song_ids = scripts.get_and_save_song_ids(artist_url)
        artist_id = artist_url.rstrip('/').split('/')[-1]
        scripts.scrape_and_save_lyrics(song_ids, artist_id=artist_id)
        print(f"ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆ{artist_id}ã®å‡¦ç†å®Œäº†")
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: {e}")
```

#### å¢—åˆ†æ›´æ–°
```python
# å®šæœŸçš„ãªæ–°æ›²ãƒã‚§ãƒƒã‚¯ã¨è¿½åŠ 
import schedule
import time

def update_artist_data():
    artist_url = "https://www.uta-net.com/artist/134/"
    song_ids = scripts.get_and_save_song_ids(artist_url)
    scripts.scrape_and_save_lyrics(song_ids, artist_id="134")
    print("ãƒ‡ãƒ¼ã‚¿æ›´æ–°å®Œäº†")

# æ¯æ—¥åˆå‰3æ™‚ã«å®Ÿè¡Œ
schedule.every().day.at("03:00").do(update_artist_data)
```

## ğŸ“Š å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿å½¢å¼

### æ¥½æ›²IDãƒ•ã‚¡ã‚¤ãƒ« (`song_ids_{artist_id}.csv`)
```csv
song_id
123456
234567
345678
```

### æ­Œè©ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ (`lyrics_data_{artist_id}.csv`)
```csv
song_id,title,artist,main_theme,lyricist,composer,arranger,release_date,cover_url,lyrics
123456,"Sample Song","Sample Artist","TVã‚¢ãƒ‹ãƒ¡ã€ŒSampleã€ä¸»é¡Œæ­Œ","ä½œè©è€…","ä½œæ›²è€…","ç·¨æ›²è€…","2023.01.01","https://...",æ­Œè©ãƒ†ã‚­ã‚¹ãƒˆ
```

#### ãƒ‡ãƒ¼ã‚¿é …ç›®è©³ç´°
| é …ç›® | èª¬æ˜ | ä¾‹ |
|------|------|-----|
| song_id | æ¥½æ›²ã®ä¸€æ„è­˜åˆ¥å­ | "123456" |
| title | æ¥½æ›²ã‚¿ã‚¤ãƒˆãƒ« | "æ®‹é…·ãªå¤©ä½¿ã®ãƒ†ãƒ¼ã‚¼" |
| artist | ã‚¢ãƒ¼ãƒ†ã‚£ã‚¹ãƒˆå | "é«˜æ©‹æ´‹å­" |
| main_theme | ä¸»é¡Œæ­Œæƒ…å ± | "TVã‚¢ãƒ‹ãƒ¡ã€Œã‚¨ãƒ´ã‚¡ãƒ³ã‚²ãƒªã‚ªãƒ³ã€ã‚ªãƒ¼ãƒ—ãƒ‹ãƒ³ã‚°ãƒ†ãƒ¼ãƒ" |
| lyricist | ä½œè©è€… | "åŠå·çœ å­" |
| composer | ä½œæ›²è€… | "ä½è—¤è‹±æ•" |
| arranger | ç·¨æ›²è€… | "å¤§æ£®ä¿Šä¹‹" |
| release_date | ç™ºå£²æ—¥ | "1995.10.25" |
| cover_url | ã‚«ãƒãƒ¼ç”»åƒURL | "https://img.uta-net.com/..." |
| lyrics | æ­Œè©å…¨æ–‡ | "æ®‹é…·ãªå¤©ä½¿ã®ãƒ†ãƒ¼ã‚¼\nçª“è¾ºã‹ã‚‰..." |

## âš™ï¸ è¨­å®šã¨ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹èª¿æ•´
```python
# scripts.pyå†…ã§èª¿æ•´å¯èƒ½ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

# ãƒªã‚¯ã‚¨ã‚¹ãƒˆé–“éš”ï¼ˆã‚µãƒ¼ãƒãƒ¼è² è·å¯¾ç­–ï¼‰
time.sleep(1)  # ç§’å˜ä½ã§èª¿æ•´å¯èƒ½

# æœ€å¤§ãƒšãƒ¼ã‚¸æ•°åˆ¶é™
max_pages = 100  # å¿…è¦ã«å¿œã˜ã¦èª¿æ•´

# ãƒãƒƒãƒã‚µã‚¤ã‚ºï¼ˆãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æœ€é©åŒ–ï¼‰
batch_size = 100  # æ¥½æ›²æ•°ãŒå¤šã„å ´åˆã¯å°ã•ãè¨­å®š
```

### ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°è¨­å®š
```python
# ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®š
response = requests.get(url, timeout=30)

# ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ã®è¿½åŠ 
import time
from functools import wraps

def retry(max_attempts=3, delay=2):
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(max_attempts):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if attempt == max_attempts - 1:
                        raise e
                    time.sleep(delay * (2 ** attempt))
            return None
        return wrapper
    return decorator
```

## ğŸ›¡ï¸ æ³¨æ„äº‹é …ã¨åˆ¶é™äº‹é …

### æ³•çš„ãƒ»å€«ç†çš„ãªè€ƒæ…®äº‹é …
- **åˆ©ç”¨è¦ç´„éµå®ˆ**: uta-net.comã®åˆ©ç”¨è¦ç´„ã‚’å¿…ãšç¢ºèª
- **è‘—ä½œæ¨©å°Šé‡**: å–å¾—ã—ãŸæ­Œè©ã®è‘—ä½œæ¨©ã¯å„æ¨©åˆ©è€…ã«å¸°å±
- **å€‹äººåˆ©ç”¨æ¨å¥¨**: å•†ç”¨åˆ©ç”¨ã¯äº‹å‰è¨±å¯ãŒå¿…è¦
- **é©åˆ‡ãªåˆ©ç”¨**: éåº¦ãªã‚¢ã‚¯ã‚»ã‚¹ã«ã‚ˆã‚‹ã‚µãƒ¼ãƒãƒ¼è² è·ã‚’é¿ã‘ã‚‹

### æŠ€è¡“çš„åˆ¶é™äº‹é …
- **ãƒ¬ãƒ¼ãƒˆåˆ¶é™**: å„ãƒªã‚¯ã‚¨ã‚¹ãƒˆå¾Œ1ç§’ã®å¾…æ©Ÿæ™‚é–“ã‚’å®Ÿè£…
- **HTMLæ§‹é€ ä¾å­˜**: ã‚µã‚¤ãƒˆæ§‹é€ å¤‰æ›´ã«ã‚ˆã‚Šå‹•ä½œä¸èƒ½ã«ãªã‚‹å¯èƒ½æ€§
- **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¾å­˜**: å®‰å®šã—ãŸã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šãŒå¿…è¦
- **ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡**: å¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†æ™‚ã¯ãƒ¡ãƒ¢ãƒªä¸è¶³ã«æ³¨æ„

### æ¨å¥¨é‹ç”¨æ–¹é‡
- **æ®µéšçš„å®Ÿè¡Œ**: å°è¦æ¨¡ãƒ†ã‚¹ãƒˆã‹ã‚‰é–‹å§‹
- **å®šæœŸçš„ç›£è¦–**: ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã®ç¢ºèªã¨å¯¾å¿œ
- **ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—**: å–å¾—ãƒ‡ãƒ¼ã‚¿ã®å®šæœŸçš„ãªãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
- **ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†**: ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å¤‰æ›´å±¥æ­´ã‚’è¨˜éŒ²

## ğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºæ–¹æ³•

#### 1. HTTPã‚¨ãƒ©ãƒ¼ï¼ˆ403, 404, 503ï¼‰
```python
# è§£æ±ºç­–: User-Agentãƒ˜ãƒƒãƒ€ãƒ¼ã®è¿½åŠ 
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}
response = requests.get(url, headers=headers)
```

#### 2. CSVãƒ•ã‚¡ã‚¤ãƒ«ã®æ–‡å­—åŒ–ã‘
```python
# è§£æ±ºç­–: ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®æ˜ç¤ºæŒ‡å®š
df = pd.read_csv('lyrics_data.csv', encoding='utf-8-sig')

# ã¾ãŸã¯ä¿å­˜æ™‚ã®è¨­å®š
df.to_csv('output.csv', encoding='utf-8-sig', index=False)
```

#### 3. ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼
```python
# è§£æ±ºç­–: ãƒãƒƒãƒå‡¦ç†ã®å®Ÿè£…
def process_in_batches(song_ids, batch_size=100):
    for i in range(0, len(song_ids), batch_size):
        batch = song_ids[i:i+batch_size]
        scripts.scrape_and_save_lyrics(batch)
        print(f"ãƒãƒƒãƒ {i//batch_size + 1} å®Œäº†")
```

#### 4. ãƒšãƒ¼ã‚¸æ§‹é€ å¤‰æ›´ã¸ã®å¯¾å¿œ
```python
# è§£æ±ºç­–: è¤‡æ•°ã®é¸æŠè‚¢ã‚’è©¦è¡Œ
def safe_find_element(soup, selectors):
    for selector in selectors:
        element = soup.find(**selector)
        if element:
            return element
    return None

# ä½¿ç”¨ä¾‹
title_selectors = [
    {"name": "h2", "class_": "ms-2 ms-md-3 kashi-title"},
    {"name": "h2", "class_": "ms-2"},
    {"name": "h1", "class_": "title"}
]
title_tag = safe_find_element(soup, title_selectors)
```

## ğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æƒ…å ±

### å‡¦ç†é€Ÿåº¦ã®ç›®å®‰
- **æ¥½æ›²IDåé›†**: ç´„20ä»¶/åˆ†ï¼ˆãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³å«ã‚€ï¼‰
- **æ­Œè©å–å¾—**: ç´„30ä»¶/åˆ†ï¼ˆè©³ç´°æƒ…å ±å«ã‚€ï¼‰
- **1,000æ›²ã®å®Œå…¨å‡¦ç†**: ç´„60-90åˆ†
- **10,000æ›²ã®å¤§è¦æ¨¡å‡¦ç†**: ç´„10-15æ™‚é–“

### ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶
- **CPU**: 1ã‚³ã‚¢ä»¥ä¸Šï¼ˆãƒãƒ«ãƒã‚³ã‚¢æ¨å¥¨ï¼‰
- **ãƒ¡ãƒ¢ãƒª**: 2GBä»¥ä¸Šï¼ˆå¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†æ™‚ã¯4GBä»¥ä¸Šï¼‰
- **ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸**: 1GBä»¥ä¸Šã®ç©ºãå®¹é‡
- **ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯**: å®‰å®šã—ãŸé«˜é€Ÿã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶š

### æœ€é©åŒ–ã®ææ¡ˆ
```python
# 1. ä¸¦åˆ—å‡¦ç†ã®å®Ÿè£…
from concurrent.futures import ThreadPoolExecutor
import threading

def parallel_scraping(song_ids, max_workers=3):
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = []
        for song_id in song_ids:
            future = executor.submit(scripts.get_song_details_and_lyrics, song_id)
            futures.append(future)
        
        results = [future.result() for future in futures]
    return results

# 2. ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°æ©Ÿèƒ½
import functools
import pickle

@functools.lru_cache(maxsize=1000)
def cached_get_song(song_id):
    return scripts.get_song_details_and_lyrics(song_id)
```

## ğŸš€ é«˜åº¦ãªä½¿ç”¨ä¾‹

### ãƒ‡ãƒ¼ã‚¿åˆ†æã¨ã®é€£æº
```python
import pandas as pd
import matplotlib.pyplot as plt
from wordcloud import WordCloud

# æ­Œè©ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨åˆ†æ
df = pd.read_csv('lyrics_data_134.csv')

# æ­Œè©ã®æ–‡å­—æ•°åˆ†æ
df['lyrics_length'] = df['lyrics'].str.len()
plt.hist(df['lyrics_length'], bins=50)
plt.title('æ­Œè©æ–‡å­—æ•°åˆ†å¸ƒ')
plt.show()

# ãƒ¯ãƒ¼ãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰ç”Ÿæˆ
all_lyrics = ' '.join(df['lyrics'].dropna())
wordcloud = WordCloud(font_path='NotoSansCJK-Regular.ttc').generate(all_lyrics)
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.show()
```

### ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹é€£æº
```python
import sqlite3

def csv_to_database(csv_file, db_file):
    # CSVã‚’SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«å¤‰æ›
    df = pd.read_csv(csv_file)
    conn = sqlite3.connect(db_file)
    df.to_sql('lyrics', conn, if_exists='replace', index=False)
    conn.close()

# ä½¿ç”¨ä¾‹
csv_to_database('lyrics_data_134.csv', 'lyrics_database.db')
```

### APIåŒ–
```python
from flask import Flask, jsonify, request

app = Flask(__name__)

@app.route('/api/lyrics/<song_id>')
def get_lyrics_api(song_id):
    try:
        song_data = scripts.get_song_details_and_lyrics(song_id)
        return jsonify(song_data)
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/artist/<artist_id>/songs')
def get_artist_songs(artist_id):
    try:
        df = pd.read_csv(f'lyrics_data_{artist_id}.csv')
        songs = df[['song_id', 'title', 'artist']].to_dict('records')
        return jsonify(songs)
    except Exception as e:
        return jsonify({'error': str(e)}), 500

if __name__ == '__main__':
    app.run(debug=True)
```

## ğŸ“š é–¢é€£ãƒªã‚½ãƒ¼ã‚¹

### å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
- [uta-net.com](https://www.uta-net.com/) - ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹
- [Beautiful Soup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
- [Pandas Documentation](https://pandas.pydata.org/docs/)
- [Requests Documentation](https://docs.python-requests.org/)

### ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã¨ã‚µãƒãƒ¼ãƒˆ
- GitHub Issues: ãƒã‚°ãƒ¬ãƒãƒ¼ãƒˆã¨æ©Ÿèƒ½è¦æœ›
- Discussions: ä½¿ç”¨æ–¹æ³•ã«é–¢ã™ã‚‹è³ªå•
- Wiki: ã‚ˆã‚Šè©³ç´°ãªæŠ€è¡“æƒ…å ±

## ğŸ¤ è²¢çŒ®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³

ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¸ã®è²¢çŒ®ã‚’æ­“è¿ã—ã¾ã™ï¼

### è²¢çŒ®ã®æ–¹æ³•
1. **ãƒªãƒã‚¸ãƒˆãƒªã®ãƒ•ã‚©ãƒ¼ã‚¯**
2. **æ©Ÿèƒ½ãƒ–ãƒ©ãƒ³ãƒã®ä½œæˆ** (`git checkout -b feature/amazing-feature`)
3. **å¤‰æ›´ã®ã‚³ãƒŸãƒƒãƒˆ** (`git commit -m 'Add amazing feature'`)
4. **ãƒ–ãƒ©ãƒ³ãƒã¸ã®ãƒ—ãƒƒã‚·ãƒ¥** (`git push origin feature/amazing-feature`)
5. **ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ä½œæˆ**

### é–‹ç™ºç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
```bash
# é–‹ç™ºç”¨ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements-dev.txt

# ã‚³ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¼ãƒãƒƒã‚¿ãƒ¼ã®å®Ÿè¡Œ
black scripts.py

# ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ
python -m pytest tests/
```

## ğŸ“„ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯å­¦ç¿’ãƒ»ç ”ç©¶ç›®çš„ã§ä½œæˆã•ã‚Œã¦ã„ã¾ã™ã€‚å•†ç”¨åˆ©ç”¨æ™‚ã¯é©åˆ‡ãªæ¨©åˆ©å‡¦ç†ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚

---

**ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ**
```bash
# 1. ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å–å¾—
git clone <repository-url>
cd uta-net

# 2. ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements.txt

# 3. ã‚µãƒ³ãƒ—ãƒ«å®Ÿè¡Œ
python -c "
import scripts
song_ids = scripts.get_and_save_song_ids('https://www.uta-net.com/artist/134/')
scripts.scrape_and_save_lyrics(song_ids[:5], artist_id='134')  # æœ€åˆã®5æ›²ã®ã¿ãƒ†ã‚¹ãƒˆ
print('ã‚µãƒ³ãƒ—ãƒ«å®Ÿè¡Œå®Œäº†ï¼')
"
```

**ğŸ“ ã‚µãƒãƒ¼ãƒˆ**
- æŠ€è¡“çš„ãªå•é¡Œ: GitHub Issues
- ä½¿ç”¨æ–¹æ³•ã®è³ªå•: GitHub Discussions
- ç·Šæ€¥ãªå•é¡Œ: ãƒ¡ãƒ³ãƒ†ãƒŠãƒ¼ã«ç›´æ¥é€£çµ¡
